{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmdfOb+dlMvziafev0pLni",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edquestofficial/Gen-AI-Cohort/blob/main/2024/april/Level_2/LLaMA_Index/1_LLaMA_Index_Hello_World_with_GeminiPro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install llama_index"
      ],
      "metadata": {
        "id": "mGNdCaP5sPzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q llama-index-llms-gemini"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNwc2YZVtMK1",
        "outputId": "5354aaad-d904-40ab-980e-1f361c2b19ac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.4/137.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive and Set `Gemini` Key"
      ],
      "metadata": {
        "id": "oqg2APAEyPOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVSp7HdEyUU-",
        "outputId": "95511ec1-379f-4ea0-bc7c-bb4f54b8c711"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/Gen AI Course/RAG_For_HDFC_Policy\"\n",
        "filepath = f\"{base_path}/gemini_api_key.txt\"\n",
        "with open(filepath, \"r\") as f:\n",
        "  api_key = ' '.join(f.readlines())\n",
        "  os.environ[\"GOOGLE_API_KEY\"] = api_key"
      ],
      "metadata": {
        "id": "IQY7JQUcycZe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM Basic Setup"
      ],
      "metadata": {
        "id": "T51QZ5aXyhEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.gemini import Gemini"
      ],
      "metadata": {
        "id": "6k5NIMGZx84j"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lR2dx300rH9T"
      },
      "outputs": [],
      "source": [
        "llm = Gemini(api_key=os.environ[\"GOOGLE_API_KEY\"], model_name=\"models/gemini-pro\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.complete(\"Tell me a joke on dog\")"
      ],
      "metadata": {
        "id": "e6YfEopVss1S"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCTaGzCDzMr_",
        "outputId": "3f6919a1-1ed3-46c6-e58f-50e5fe30611c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletionResponse(text='Why did the dog go to the bank?\\n\\nTo get his loan approved!', additional_kwargs={}, raw={'content': {'parts': [{'text': 'Why did the dog go to the bank?\\n\\nTo get his loan approved!'}], 'role': 'model'}, 'finish_reason': 1, 'index': 0, 'safety_ratings': [], 'token_count': 0, 'grounding_attributions': [], 'block_reason': 0}, logprobs=None, delta=None)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "IW8Vu4DjzPnh",
        "outputId": "a2b4b600-ee77-4fab-a758-7008cc03b563"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Why did the dog go to the bank?\n\nTo get his loan approved!"
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KUOVwK6tzm_2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}